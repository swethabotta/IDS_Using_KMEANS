# -*- coding: utf-8 -*-
"""KMeans_IDS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16ijcPzcH2wCJJuQoSnmUdmqWE9v7s4s4
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.cluster import KMeans
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.metrics import silhouette_score, confusion_matrix, accuracy_score, f1_score, precision_score, classification_report, make_scorer
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
import time
import sys
import seaborn as sns

def load_data(file_path):
    return pd.read_csv(file_path, header=None, names=['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'attack', 'level'])

def preprocess_data(data):
    features = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate']
    X = data[features].copy()

    # Encoding categorical features
    X['protocol_type'] = LabelEncoder().fit_transform(X['protocol_type'])
    X['service'] = LabelEncoder().fit_transform(X['service'])
    X['flag'] = LabelEncoder().fit_transform(X['flag'])

    # Scaling numerical features
    scaler = MinMaxScaler()
    X = pd.DataFrame(scaler.fit_transform(X), columns=features)

    # Selecting top features using SelectKBest
    y = data['attack'].apply(lambda x: 0 if x == "normal" else 1)
    selector = SelectKBest(score_func=chi2, k=10)
    X_new = selector.fit_transform(X, y)

    # Getting the selected feature names
    mask = selector.get_support()
    selected_features = [feature for bool_val, feature in zip(mask, features) if bool_val]
    print("Selected Features:", selected_features)

    return X_new, y, selected_features

def silhouette_scorer(X, labels):
    return silhouette_score(X, labels)

silhouette_scorer = make_scorer(silhouette_scorer, needs_proba=False)

def train_evaluate_model(X_train, X_test, y_train, y_test, n_clusters):
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    kmeans.fit(X_train)
    y_pred = kmeans.predict(X_test)
    train_score = silhouette_score(X_train, kmeans.labels_)
    test_score = silhouette_score(X_test, y_pred)
    conf_matrix = confusion_matrix(y_test, y_pred)
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='binary')
    precision = precision_score(y_test, y_pred, average='binary')
    report = classification_report(y_test, y_pred)
    return kmeans, train_score, test_score, conf_matrix, accuracy, f1, precision, report

def calculate_complexity(train_data, X_train, X_test, kmeans):
    space_complexity = {
        'train_data': sys.getsizeof(train_data),
        'X_train': sys.getsizeof(X_train),
        'X_test': sys.getsizeof(X_test),
        'kmeans': sys.getsizeof(kmeans)
    }
    total_space_complexity = sum(space_complexity.values())
    return space_complexity, total_space_complexity

def train_and_evaluate(file_path_train, file_path_test=None, split_data=True, use_pca=False):
    start_time = time.time()

    # Loading training data
    train_data = load_data(file_path_train)

    # Preprocessing training data
    X_train, y_train, selected_features = preprocess_data(train_data)

    # Applying PCA if specified
    if use_pca:
        pca = PCA(n_components=2)
        X_train = pca.fit_transform(X_train)

    if not split_data:
        # Loading testing data
        test_data = load_data(file_path_test)
        X_test, y_test, _ = preprocess_data(test_data)

        # Applying PCA if specified
        if use_pca:
            X_test = pca.transform(X_test)
    else:
        # Splitting data into train and test sets
        X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

    # Defining parameter grid for hyperparameter tuning
    param_grid = {'n_clusters': range(2, 11)}

    # Performing hyperparameter tuning
    kmeans_grid = GridSearchCV(KMeans(random_state=42), param_grid, scoring=silhouette_scorer, cv=3, n_jobs=-1)
    kmeans_grid.fit(X_train)

    # Getting the best hyperparameters
    best_params = kmeans_grid.best_params_
    best_n_clusters = best_params['n_clusters']

    # Training and evaluating model with the best hyperparameters
    kmeans, train_score, test_score, conf_matrix, accuracy, f1, precision, report = train_evaluate_model(X_train, X_test, y_train, y_test, best_n_clusters)

    # Calculating complexity
    space_complexity, total_space_complexity = calculate_complexity(train_data, X_train if split_data else X_train, X_test, kmeans)

    # Printing results
    print(f"Best Hyperparameters: {best_params}")
    print(f"Number of Clusters: {best_n_clusters}")
    print(f"Silhouette Score (Train): {train_score:.2f}")
    print(f"Silhouette Score (Test): {test_score:.2f}")
    print("\nConfusion Matrix:")
    print(conf_matrix)
    print(f"\nAccuracy: {accuracy:.2f}")
    print(f"F1-Score: {f1:.2f}")
    print(f"Precision: {precision:.2f}")
    print("\nClassification Report:")
    print(report)
    for obj, size in space_complexity.items():
        print(f"Space Complexity of {obj}: {size} bytes")
    print(f"Total Space Complexity: {total_space_complexity} bytes")

    # Plotting the confusion matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g')
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.show()

    # Recording end time
    end_time = time.time()

    # Calculating execution time
    execution_time = end_time - start_time
    print("Execution Time:", execution_time, "seconds")

if __name__ == "__main__":
    option_split = input("Do you want to split the data into train and test sets? (yes/no): ").lower()
    option_pca = input("Do you want to use PCA? (yes/no): ").lower()

    if option_split == "yes":
        if option_pca == "yes":
            train_and_evaluate("/content/KDDTrain+.txt", split_data=True, use_pca=True)
        elif option_pca == "no":
            train_and_evaluate("/content/KDDTrain+.txt", split_data=True, use_pca=False)
        else:
            print("Invalid option for PCA! Please enter 'yes' or 'no'.")
    elif option_split == "no":
        if option_pca == "yes":
            train_and_evaluate("/content/KDDTrain+.txt", file_path_test="/content/KDDTest+.txt", split_data=False, use_pca=True)
        elif option_pca == "no":
            train_and_evaluate("/content/KDDTrain+.txt", file_path_test="/content/KDDTest+.txt", split_data=False, use_pca=False)
        else:
            print("Invalid option for PCA! Please enter 'yes' or 'no'.")
    else:
        print("Invalid option for splitting! Please enter 'yes' or 'no'.")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.cluster import KMeans
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif
from sklearn.metrics import silhouette_score, confusion_matrix, accuracy_score, f1_score, precision_score, classification_report, make_scorer
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
import time
import sys
import seaborn as sns

def load_data(file_path):
    return pd.read_csv(file_path, header=None, names=['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'attack', 'level'])

def preprocess_data(data):
    features = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate']
    X = data[features].copy()

    # Encoding categorical features
    X['protocol_type'] = LabelEncoder().fit_transform(X['protocol_type'])
    X['service'] = LabelEncoder().fit_transform(X['service'])
    X['flag'] = LabelEncoder().fit_transform(X['flag'])

    # Scaling numerical features
    scaler = MinMaxScaler()
    X = pd.DataFrame(scaler.fit_transform(X), columns=features)

    # Selecting top features using SelectKBest with chi2 and mutual_info_classif
    y = data['attack'].apply(lambda x: 0 if x == "normal" else 1)
    selector_chi2 = SelectKBest(score_func=chi2, k=10)
    X_chi2 = selector_chi2.fit_transform(X, y)

    selector_mutual_info = SelectKBest(score_func=mutual_info_classif, k=10)
    X_mutual_info = selector_mutual_info.fit_transform(X, y)

    # Combining features selected by both methods
    selected_features_chi2 = [feature for bool_val, feature in zip(selector_chi2.get_support(), features) if bool_val]
    selected_features_mutual_info = [feature for bool_val, feature in zip(selector_mutual_info.get_support(), features) if bool_val]
    selected_features = list(set(selected_features_chi2 + selected_features_mutual_info))
    X = X[selected_features]
    print("Selected Features:", selected_features)

    return X, y

def silhouette_scorer(X, labels):
    return silhouette_score(X, labels)

silhouette_scorer = make_scorer(silhouette_scorer, needs_proba=False)

def train_evaluate_model(X_train, X_test, y_train, y_test, n_clusters):
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    kmeans.fit(X_train)
    y_pred = kmeans.predict(X_test)
    train_score = silhouette_score(X_train, kmeans.labels_)
    test_score = silhouette_score(X_test, y_pred)
    conf_matrix = confusion_matrix(y_test, y_pred)
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='binary')
    precision = precision_score(y_test, y_pred, average='binary')
    report = classification_report(y_test, y_pred)
    return kmeans, train_score, test_score, conf_matrix, accuracy, f1, precision, report

def calculate_complexity(train_data, X_train, X_test, kmeans):
    space_complexity = {
        'train_data': sys.getsizeof(train_data),
        'X_train': sys.getsizeof(X_train),
        'X_test': sys.getsizeof(X_test),
        'kmeans': sys.getsizeof(kmeans)
    }
    total_space_complexity = sum(space_complexity.values())
    return space_complexity, total_space_complexity

def train_and_evaluate(file_path_train, file_path_test=None, split_data=True, use_pca=False):
    start_time = time.time()

    # Loading training data
    train_data = load_data(file_path_train)

    # Preprocessing training data
    X_train, y_train = preprocess_data(train_data)

    # Applying PCA if specified
    if use_pca:
        pca = PCA(n_components=2)
        X_train = pca.fit_transform(X_train)

    if not split_data:
        # Loading testing data
        test_data = load_data(file_path_test)
        X_test, y_test = preprocess_data(test_data)

        # Applying PCA if specified
        if use_pca:
            X_test = pca.transform(X_test)
    else:
        # Balancing the dataset using SMOTE
        smote = SMOTE(random_state=42)
        X_train, y_train = smote.fit_resample(X_train, y_train)

        # Splitting data into train and test sets
        X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

    # Defining parameter grid for hyperparameter tuning
    param_grid = {'n_clusters': range(2, 11)}

    # Performing hyperparameter tuning
    kmeans_grid = GridSearchCV(KMeans(random_state=42), param_grid, scoring=silhouette_scorer, cv=3, n_jobs=-1)
    kmeans_grid.fit(X_train)

    # Getting the best hyperparameters
    best_params = kmeans_grid.best_params_
    best_n_clusters = best_params['n_clusters']

    # Training and evaluating model with the best hyperparameters
    kmeans, train_score, test_score, conf_matrix, accuracy, f1, precision, report = train_evaluate_model(X_train, X_test, y_train, y_test, best_n_clusters)

    # Calculating complexity
    space_complexity, total_space_complexity = calculate_complexity(train_data, X_train if split_data else X_train, X_test, kmeans)

    # Printing results
    print(f"Best Hyperparameters: {best_params}")
    print(f"Number of Clusters: {best_n_clusters}")
    print(f"Silhouette Score (Train): {train_score:.2f}")
    print(f"Silhouette Score (Test): {test_score:.2f}")
    print("\nConfusion Matrix:")
    print(conf_matrix)
    print(f"\nAccuracy: {accuracy:.2f}")
    print(f"F1-Score: {f1:.2f}")
    print(f"Precision: {precision:.2f}")
    print("\nClassification Report:")
    print(report)
    for obj, size in space_complexity.items():
        print(f"Space Complexity of {obj}: {size} bytes")
    print(f"Total Space Complexity: {total_space_complexity} bytes")

    # Plotting the confusion matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g')
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.show()

    # Recording end time
    end_time = time.time()

    # Calculating execution time
    execution_time = end_time - start_time
    print("Execution Time:", execution_time, "seconds")

if __name__ == "__main__":
    option_split = input("Do you want to split the data into train and test sets? (yes/no): ").lower()
    option_pca = input("Do you want to use PCA? (yes/no): ").lower()

    if option_split == "yes":
        if option_pca == "yes":
            train_and_evaluate("/content/KDDTrain+.txt", split_data=True, use_pca=True)
        elif option_pca == "no":
            train_and_evaluate("/content/KDDTrain+.txt", split_data=True, use_pca=False)
        else:
            print("Invalid option for PCA! Please enter 'yes' or 'no'.")
    elif option_split == "no":
        if option_pca == "yes":
            train_and_evaluate("/content/KDDTrain+.txt", file_path_test="/content/KDDTest+.txt", split_data=False, use_pca=True)
        elif option_pca == "no":
            train_and_evaluate("/content/KDDTrain+.txt", file_path_test="/content/KDDTest+.txt", split_data=False, use_pca=False)
        else:
            print("Invalid option for PCA! Please enter 'yes' or 'no'.")
    else:
        print("Invalid option for splitting! Please enter 'yes' or 'no'.")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.cluster import KMeans
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif
from sklearn.metrics import silhouette_score, confusion_matrix, accuracy_score, f1_score, precision_score, classification_report, make_scorer
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
import time
import sys
import seaborn as sns

def load_data(file_path):
    return pd.read_csv(file_path, header=None, names=['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'attack', 'level'])

def preprocess_data(data):
    features = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate']
    X = data[features].copy()

    # Encoding categorical features
    X['protocol_type'] = LabelEncoder().fit_transform(X['protocol_type'])
    X['service'] = LabelEncoder().fit_transform(X['service'])
    X['flag'] = LabelEncoder().fit_transform(X['flag'])

    # Scaling numerical features
    scaler = MinMaxScaler()
    X = pd.DataFrame(scaler.fit_transform(X), columns=features)

    # Selecting top features using SelectKBest with chi2 and mutual_info_classif
    y = data['attack'].apply(lambda x: 0 if x == "normal" else 1)
    selector_chi2 = SelectKBest(score_func=chi2, k=10)
    X_chi2 = selector_chi2.fit_transform(X, y)

    selector_mutual_info = SelectKBest(score_func=mutual_info_classif, k=10)
    X_mutual_info = selector_mutual_info.fit_transform(X, y)

    # Combining features selected by both methods
    selected_features_chi2 = [feature for bool_val, feature in zip(selector_chi2.get_support(), features) if bool_val]
    selected_features_mutual_info = [feature for bool_val, feature in zip(selector_mutual_info.get_support(), features) if bool_val]
    selected_features = list(set(selected_features_chi2 + selected_features_mutual_info))
    X = X[selected_features]
    print("Selected Features:", selected_features)

    return X, y

def silhouette_scorer(X, labels):
    return silhouette_score(X, labels)

silhouette_scorer = make_scorer(silhouette_scorer, needs_proba=False)

def train_evaluate_model(X_train, X_test, y_train, y_test, n_clusters):
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    kmeans.fit(X_train)
    y_pred = kmeans.predict(X_test)
    train_score = silhouette_score(X_train, kmeans.labels_)
    test_score = silhouette_score(X_test, y_pred)
    conf_matrix = confusion_matrix(y_test, y_pred)
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='binary')
    precision = precision_score(y_test, y_pred, average='binary')
    report = classification_report(y_test, y_pred)
    return kmeans, train_score, test_score, conf_matrix, accuracy, f1, precision, report

def calculate_complexity(train_data, X_train, X_test, kmeans):
    space_complexity = {
        'train_data': sys.getsizeof(train_data),
        'X_train': sys.getsizeof(X_train),
        'X_test': sys.getsizeof(X_test),
        'kmeans': sys.getsizeof(kmeans)
    }
    total_space_complexity = sum(space_complexity.values())
    return space_complexity, total_space_complexity

def train_and_evaluate(file_path_train, file_path_test=None, split_data=True, use_pca=False):
    start_time = time.time()

    # Loading training data
    train_data = load_data(file_path_train)

    # Preprocessing training data
    X_train, y_train = preprocess_data(train_data)

    # Applying PCA if specified
    if use_pca:
        pca = PCA(n_components=2)
        X_train = pca.fit_transform(X_train)

    if not split_data:
        # Loading testing data
        test_data = load_data(file_path_test)
        X_test, y_test = preprocess_data(test_data)

        # Applying PCA if specified
        if use_pca:
            X_test = pca.transform(X_test)
    else:
        # Balancing the dataset using SMOTE
        smote = SMOTE(random_state=42)
        X_train, y_train = smote.fit_resample(X_train, y_train)

        # Splitting data into train and test sets
        X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

    # Defining parameter grid for hyperparameter tuning
    param_grid = {'n_clusters': range(2, 11)}

    # Performing hyperparameter tuning
    kmeans_grid = GridSearchCV(KMeans(random_state=42), param_grid, scoring=silhouette_scorer, cv=3, n_jobs=-1)
    kmeans_grid.fit(X_train)

    # Getting the best hyperparameters
    best_params = kmeans_grid.best_params_
    best_n_clusters = best_params['n_clusters']

    # Training and evaluating model with the best hyperparameters
    kmeans, train_score, test_score, conf_matrix, accuracy, f1, precision, report = train_evaluate_model(X_train, X_test, y_train, y_test, best_n_clusters)

    # Calculating complexity
    space_complexity, total_space_complexity = calculate_complexity(train_data, X_train if split_data else X_train, X_test, kmeans)

    # Printing results
    print(f"Best Hyperparameters: {best_params}")
    print(f"Number of Clusters: {best_n_clusters}")
    print(f"Silhouette Score (Train): {train_score:.2f}")
    print(f"Silhouette Score (Test): {test_score:.2f}")
    print("\nConfusion Matrix:")
    print(conf_matrix)
    print(f"\nAccuracy: {accuracy:.2f}")
    print(f"F1-Score: {f1:.2f}")
    print(f"Precision: {precision:.2f}")
    print("\nClassification Report:")
    print(report)
    for obj, size in space_complexity.items():
        print(f"Space Complexity of {obj}: {size} bytes")
    print(f"Total Space Complexity: {total_space_complexity} bytes")

    # Plotting the confusion matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g')
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.show()

    # Recording end time
    end_time = time.time()

    # Calculating execution time
    execution_time = end_time - start_time
    print("Execution Time:", execution_time, "seconds")

if __name__ == "__main__":
    option_split = input("Do you want to split the data into train and test sets? (yes/no): ").lower()
    option_pca = input("Do you want to use PCA? (yes/no): ").lower()

    if option_split == "yes":
        if option_pca == "yes":
            train_and_evaluate("/content/KDDTrain+.txt", split_data=True, use_pca=True)
        elif option_pca == "no":
            train_and_evaluate("/content/KDDTrain+.txt", split_data=True, use_pca=False)
        else:
            print("Invalid option for PCA! Please enter 'yes' or 'no'.")
    elif option_split == "no":
        if option_pca == "yes":
            train_and_evaluate("/content/KDDTrain+.txt", file_path_test="/content/KDDTest+.txt", split_data=False, use_pca=True)
        elif option_pca == "no":
            train_and_evaluate("/content/KDDTrain+.txt", file_path_test="/content/KDDTest+.txt", split_data=False, use_pca=False)
        else:
            print("Invalid option for PCA! Please enter 'yes' or 'no'.")
    else:
        print("Invalid option for splitting! Please enter 'yes' or 'no'.")

